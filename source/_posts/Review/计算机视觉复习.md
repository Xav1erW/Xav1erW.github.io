---
title: 计算机视觉
date: 2023.5.31
author: Xav1er
categories:	
  - Review
tags:
  - 计算机视觉
  - 课内
  - 复习
---

# 滤波

高斯核的性质：

* 使用小方差的高斯核卷积多次和一个大的方差的高斯核卷积效果一样，比如使用方差为$\sigma$ 的高斯核卷积两次，和使用方差为$\sqrt 2\sigma$ 的高斯核卷积一次效果一样。上述关系类似勾股定理，第一次使用 $m\sigma$卷积，第二次使用$n\sigma$卷积，结果相当于使用$\sqrt{m^2+n^2}\sigma$卷积

  m\*m卷积核卷积n\*n的图像，复杂度从$O(n^2m^2)$变为$O(n^2m)$

* 高斯卷积核可以分解为x和y方向，分解为两个方向分别卷积

* 选择卷积核大小：中心左右各3sigma，filter size：$2\cdot3\sigma +1$

中值滤波：

使用卷积核中的中间值作为输出（可以类比max pooling，看作median pooling），可以去除椒盐噪声或白噪声

# 边缘

Sobel算子：相当于先高斯后梯度
$$
\begin{bmatrix}
-1 & 0 & 1\\
-2 & 0 & 2\\
-1 & 0 & 1\\
\end{bmatrix} 
=
\begin{bmatrix}
1\\
2\\
1\\
\end{bmatrix} 
\begin{bmatrix}
-1 & 0 & 1
\end{bmatrix}
$$
Riberts算子：Mx检测135°的My检测45°
$$
M_x = \begin{bmatrix}
0 & 1\\
-1 & 0
\end{bmatrix}
\qquad
M_y = \begin{bmatrix}
1 & 0\\
0 & -1
\end{bmatrix}
$$
实际使用为了去除噪声，需要先高斯平滑，再提取边缘，这需要两次卷积：

![image-20230531145355816](https://raw.githubusercontent.com/Xav1erW/blog-imgs/master/202305311453930.png)



为了合并成一次卷积，利用结合率 $\frac{d}{dx} (f * g) = f *\frac{d}{dx}g$ （求导也是卷积因此满足结合律，先对高斯求导，使用求导出的东西卷积），出来一个高斯偏导模板，类似高斯核，不过是使用**高斯函数的导数**去填充，即x方向上使用$\frac{\partial}{\partial x} \frac{1}{2\pi\sigma^2} \exp(-\frac{x^2+y^2}{2\sigma^2})$ 函数填充，y方向类似：

![image-20230531145436679](https://raw.githubusercontent.com/Xav1erW/blog-imgs/master/202305311454052.png)

<img src="https://raw.githubusercontent.com/Xav1erW/blog-imgs/master/202305311845235.png" alt="image-20230531184557769" style="zoom:50%;" />

x-direction水平梯度，竖直边缘，y-direction垂直梯度，水平边缘

# 最小二乘&RANSAC

最小二乘，检测线，只在垂直方向：对于$XB=Y$的方程（$B=[m\ b]^T$）最优解满足
$$
X^T XB = X^T Y
$$
对于矩阵乘法：$AX=0$，那么使矩阵$A$特征值为0的特征向量就是解。

鲁棒的最小二乘：相当于阈值化距离，当距离过长时对error的贡献和较近的点类似，如下图，可以认为距离10和距离4最终error一样都是1

![image-20230530082917155](https://raw.githubusercontent.com/Xav1erW/blog-imgs/master/202305300829465.png)

参数选择：$\sigma$ 选择最小二乘后的平均残差的1.5倍

## RANSAC

迭代次数选择：根据迭代次数和外点率可以求得得到的直线的置信度
$$
(1-(1-e)^s)^N = 1-p
$$
其中s时估计曲线需要的点的个数，对于直线就是2，e为外点率，不属于直线的点

RANSAC算出一条线后还会将所有内点最小二乘算出最终的线

# 霍夫变换

求直线：直接用$y = ax+b$也可以做，但是参数没有边界，同时无法表达垂直的线

因此换成极坐标表示：
$$
x\cos \theta+y\sin\theta=\rho
$$
$\theta$可以在0-180穷举，还可改进，因为直线的点上梯度的方向垂直于线，可以通过梯度进一步缩小theta的搜索范围

## 噪声处理

* 选择更好网格或者离散化，如果噪声多可以网格大一点，但是会不够准确
* 提高邻居格子的评分（软门限），比如投票到某一格子，给该各自周边的bin也根据距离投票，比如中心投票加0.1，距离为1的加0.05，距离为2的加0.01，**总分为1**
* 减少外点数：只统计边缘的点和更确定的投票，比如对于直线，只投票梯度theta方向或theta附近方向投票

# Harris角点

好的特征的特性：

* 可靠性，在不同的角度、不同的图片中都能有这个特征
* 显著性：不能太平庸，得有代表性，不能和别的长得太像
* 计算高效
* 只和局部相关

角点检测，通过移动窗口并对前后的窗口相减就可以看出变化
$$
E(u,v) = \sum_{x,y} w(x,y) [I(x+u, y+v)-I(x,y)]^2
$$
x,y为窗口内坐标，u,v为窗口移动的距离

将上式用泰勒展开，最后只会留下二阶项（0，1阶为0）
$$
E(u,v)=[u\quad v]\begin{bmatrix}E_{uu}(0,0) & E_{uv}(0,0)\\ E_{uv}(0,0) & E_{vv}(0,0)\end{bmatrix} [u\quad v]^T
$$
由于$E_{uu}(0,0) = \sum_{x,y}2w(x,y)I_x(x,y)I_x(x,y)$ 其他也可表示为类似的，最终可以表示为
$$
E(u,v)=[u\quad v]M [u\quad v]^T\\
M = \sum_{x,y}w(x,y) \begin{bmatrix}I_x^2 & I_x I_y\\ I_x I_y & I_y^2\end{bmatrix}
$$
如果我们的角的两边分别和图片的长宽平行，那么M是一个对角矩阵，对应着一个垂直坐标轴的椭圆（因为上述是一个二次项，可以表示为一个椭圆），否则M四个元素都不为0，对应一个旋转的椭圆。我们可以进行对角化将其转化
$$
M = R^{-1}\begin{bmatrix}\lambda_1 & 0\\ 0 & \lambda_2\end{bmatrix} R
$$
那么最终可以表示为
$$
E(u,v)&=[u\quad v] R^{-1} M' R[u\quad v]^T\\
&= (R[u\quad v])^T M'(R[u\quad v]^T)
$$
注：因为R正交所以转置和逆相等

这样就相当于把角旋转正。上面的lambda1，2是和椭圆的轴有关，$\sqrt{1/\lambda}$ 是轴的长度，lambda越大，轴越短，**那么lambda越大那么梯度变化越快**

最终可以分为如下情况：

* lambda1，2都很小，变化都不强烈，所以是平坦区域
* lamdba1>>lambda2或反过来，只在一个方向变化大，是边
* 都很大，是角点

最终判断通过公式：
$$
R = \det(M) - \alpha \trace(M) = \lambda_1\lambda_2 - \alpha (\lambda_1+\lambda_2)^2
$$
alpha经验值，取0.04到0.06，用M的行列式，减去M的迹（对角元素和），这样不用求特征值，对于$M=\begin{bmatrix}a&c\\c&b\end{bmatrix}$ 直接用$(ab-c^2)-\alpha(a+b)$

最终$R>0$是角点，$R<0$是边，$R\approx 0$ 是平坦区域

总体流程：

1. 计算每个点的梯度（x和y方向的）
2. 计算每个像素的二阶矩矩阵（需要每个像素画个小框计算M，并且用高斯加权，中心权重大，周围权重低）
3. 计算R
4. 根据R的阈值保留可能的角点
5. 非极大抑制（在窗口内取最大的值）

观察代码实现：一半提取梯度和高斯统一使用Sobel完成（因为Sobel可以看作高斯核与梯度核的结合）

特点：

* 光照或亮度的变换$I \to aI+b$，如果整体亮度变化，$I \to I+b$，因为只用了导数方向，影响不大但如果$I \to aI$ 可能导致部分R可能小于或大于门限，对最终结果产生影响 invariance
* shift平移，比如角在0，0和在5，5，点都会检测出来，但位置会不同，需要经过一个平移变换，因此是covariance（经过一些变换能够对应上）
* 旋转：同样是covariance
* 尺度：图像放大缩小：可以考虑极端的，如果一个角放大足够大，也会变得平滑而不是角点，因此不是尺度不变的

# SIFT(Blob检测)

出发点：希望找到一种尺度不变的特征（针对角点的缺点），希望这个特征针对尺度是covariance的

可视化：希望找到一个特征选择器，给一个点向周围画圆，到合适大小时这个圆半径得分最高，之前之后都小

![image-20230531144754559](https://raw.githubusercontent.com/Xav1erW/blog-imgs/master/202305311448309.png)

回忆之前：找边缘的时候，使用高斯偏导模板对信号卷积，相当于先高斯后偏导，在边缘处得到最大的响应，那么我们如果对高斯求二阶偏导呢？结果如下图：

![image-20230531145857202](https://raw.githubusercontent.com/Xav1erW/blog-imgs/master/202305311458533.png)

边缘就是过零点的地方，二阶导也叫做**拉普拉斯核**

高斯核、一阶导、拉普拉斯核都遵循经验公式：filter size=$2\cdot3\sigma +1$，因此只用指定一个参数$\sigma$

当我们用固定参数的拉普拉斯核卷积不同大小的信号时，边缘可以看作是一个涟漪，而当信号和核的参数尺度匹配时，两个涟漪叠加形成一个极大值：

![image-20230531150457845](https://raw.githubusercontent.com/Xav1erW/blog-imgs/master/202305311504184.png)

上图可以看出卷积核参数与信号的匹配性，那么我们如果使用不同的模板参数卷积，找出最大的模板参数就能得到尺度信息。但是使用拉普拉斯卷积，当方差过大时($\sigma$)，信号会被衰减，无法比较。

因为高斯偏导模板积分出来面积为 $\frac{1}{\sigma \sqrt{2\pi}}$ 为了使不受sigma影响，因此应当补偿乘一个sigma，而拉普拉斯是二阶导，因此补偿一个 $\sigma^2$，补偿前后效果：

![image-20230531151730304](https://raw.githubusercontent.com/Xav1erW/blog-imgs/master/202305311517087.png)

将上述卷积结果的中心连在一起看就可以看出本章第一张图的效果，即圆的半径和得分的关系。

需要在x、y方向上分别应用这个核：
$$
\nabla^2g = \frac{\partial^2g}{\partial x^2}+\frac{\partial^2g}{\partial y^2}\\
\nabla_{\text{norm}}^2g =\sigma^2\left( \frac{\partial^2g}{\partial x^2}+\frac{\partial^2g}{\partial y^2}\right)
$$
拉普拉斯核方差和图像上半径的关系：$\sigma=r/\sqrt 2$，结论：最大响应时信号的宽度正好和拉普拉斯核的0平面部分宽度一样

![image-20230531153213179](https://raw.githubusercontent.com/Xav1erW/blog-imgs/master/202305311532211.png)



使用时使用多个尺度去卷积，得到一系列的尺度表达：

<img src="https://raw.githubusercontent.com/Xav1erW/blog-imgs/master/202305311542411.png" alt="image-20230531154227252" style="zoom:50%;" /><img src="https://raw.githubusercontent.com/Xav1erW/blog-imgs/master/202305311542457.png" alt="image-20230531154242805" style="zoom:50%;" /><img src="https://raw.githubusercontent.com/Xav1erW/blog-imgs/master/202305311543672.png" alt="image-20230531154304491" style="zoom:50%;" /><img src="https://raw.githubusercontent.com/Xav1erW/blog-imgs/master/202305311543534.png" alt="image-20230531154321345" style="zoom:50%;" /><img src="https://raw.githubusercontent.com/Xav1erW/blog-imgs/master/202305311543913.png" alt="image-20230531154336725" style="zoom:50%;" /><img src="https://raw.githubusercontent.com/Xav1erW/blog-imgs/master/202305311545591.png" alt="image-20230531154529024" style="zoom:50%;" />

每三个相邻尺度为一组，看中间的的尺度是否是极大的，如果是，那么认为该尺度得到了匹配。（因为是三个相邻尺度比较，所以总体上一个点可能有多次被匹配，一个点画好几个圆）；因为一个点不仅有上下的不同尺度，还有同尺度的不同空间位置，因此在这里非极大抑制，只有中心点比周围26个点都大，才胜出

![image-20230531154152541](https://raw.githubusercontent.com/Xav1erW/blog-imgs/master/202305311830249.png)

拉普拉斯如果全图搜索的话，需要做很多不同尺度的卷积，运算量很大，那么有两个个改进：

* Harris-Laplacian：在角点附近搜索特征点
* SIFT：Scale-Invariant Feature Transform

## SIFT

提出了laplacian的改进：高斯差分DoG，结果和拉普拉斯很像：$G(x,y,k\sigma)-G(x,y,\sigma) \approx (k-1)\sigma^2\nabla^2G$

![image-20230531155452703](https://raw.githubusercontent.com/Xav1erW/blog-imgs/master/202305311554405.png)

因为高斯核有个性质，大高斯核的卷积结果能够用多次小高斯核的结果得到，减少了卷积运算量（大卷积核运算量更大）

与拉普拉斯的对应关系：$\sigma \to \sigma_{lap}\quad k\sigma \to k\sigma_{lap}$ ，最终结果只相差一个常数$k-1$，相差一个常数无所谓，因为最终只对比相对大小，都差一个常数相当于都不差，依次类推

后者：相当于$G(x,y,k^2\sigma)-G(x,y,k\sigma) = (k-1)(k\sigma)^2\nabla^2G$ 是$k\sigma$尺度下的拉普拉斯响应的常数缩放(k-1)

![image-20230531155901455](https://raw.githubusercontent.com/Xav1erW/blog-imgs/master/202305311559445.png)

同时，利用高斯核的特性：$k\sigma$的结果只需要在$\sigma$上再用$\sqrt{(k\sigma)^2-\sigma^2}$ 卷积就好，这个卷积核比$k\sigma$的卷积核小，提高了效率。

SIFT还把图像缩小到1/2，1/4等等不同大小，这样同样的核卷积出来的结果尺度大多个倍数，也不用更大的卷积核来做，减小了运算量同时检测到了更大尺度的特征。比如使用sigma=1检测到了特征，如果是原图上，这个特征对应的区域半径是$\sqrt2$，那么在缩小的图像检测出的，对应到原图上就是半径$2\sqrt2$的区域。

因此SIFT不同尺度区域的sigma是通过缩放图像不同倍数得到的，比如1-2的尺度在原图上卷积得到，2-4的尺度在缩小1/2的图上，4-8的尺度在缩小到1/4的图上得到。

k如何设置？$k=2^{1/s}$，其中s代表最终能输出多少个尺度，上图为例，一共得到了四个高斯差分，每相邻三个高斯差分的中间能得到一个最终的尺度表达，那么四个最终能输出$k\sigma$和$k^2\sigma$2个尺度的表达，因此$s=2$

这样能够形成连续的尺度空间，因此最初的高斯的层数取决于选择的s。

并且对于上图的情况，我们通常把倒数第三层直接下采样，就变成了上一级octave的第一层

### 有关不变性

拉普拉斯的响应：旋转和尺度不变invariant

Blob的位置和尺度是旋转和尺度的协变covariant

SIFT对于视角不是不变的，因为视角改变，圆可能变成椭圆

<img src="https://raw.githubusercontent.com/Xav1erW/blog-imgs/master/202305311652488.png" alt="image-20230531165207292" style="zoom:50%;" />

如果想对**视角变化**有一定鲁棒性：给出圆，然后计算圆内所有像素的M矩阵（Harris角点），看两个特征值，如果两个特征值相差多，把最初的圆在小特征值方向压扁成一个椭圆，再计算椭圆区域的M，重复上述步骤，直到区域内两个特征值差不多。仿射自适应。

我们依据仿射自适应把两个区域变化到一样的**大小**，可以发现内容基本一致，但是方向不同

<img src="https://raw.githubusercontent.com/Xav1erW/blog-imgs/master/202305311706603.png" alt="image-20230531170236537" style="zoom:50%;" />

为了处理**角度**不同：基于梯度方向。求出整个SIFT区域每个点的梯度强度和方向，画出梯度方向直方图（0-360分为8份），落到哪个方向范围就在对应的方向范围加上梯度的强度，以此得到信号变化最大的方向，根据这个方向将图旋转使方向归0

<img src="https://raw.githubusercontent.com/Xav1erW/blog-imgs/master/202305311706876.png" alt="image-20230531170631160" style="zoom:50%;" />

为了处理**亮度**的不同，最终使用梯度描述区域特征：最后把区域分为4*4=16份，同时每个小格分别统计梯度方向直方图，量化为8份（同上），将这8个数作为该小区域的一个描述，一共16个区域形成一个128维的向量作为区域的描述符

<img src="https://raw.githubusercontent.com/Xav1erW/blog-imgs/master/202305311713622.png" alt="image-20230531171316574" style="zoom:50%;" />

SIFT描述符不局限于SIFT算法：Harris+Laplacian也可以得到区域，也可以使用sift描述符表示。

拆分成小格：在局部上做直方图上统计，能够保留一些空间特征（patch顺序保留了一些空间信息）

## SIFT特征匹配

两张对同一物品的图片如何匹配SIFT特征，两两计算特征距离，但是如何定义门限？

对于一个特征，看与他匹配的另一张图的特征的第一近邻和第二近邻的距离，如果差异较大，说明匹配成功；如果差异不大说明匹配模糊，可能错误丢弃

# 纹理

用处：

1. 从纹理中恢复形状（从纹理的变化）
2. 分割或分类：不同物体的纹理特性不同，识别不同的材质，识别水果，区分动物。
3. 合成：给定纹理合成更多的纹理，下图给出了纹理的分类和合成区别

<img src="https://raw.githubusercontent.com/Xav1erW/blog-imgs/master/202305311835755.png" alt="image-20230531183549426" style="zoom:50%;" />

希望找到一种特征比边缘更高级，表示纹理。

纹理由重复的一些模式构成，那么我们需要发现模式，描述区域里模式的关系。

纹理表示：分成小窗口，计算水平和垂直梯度，表示到二维平面上，可以看出能够分为几类，可以使用kmeans聚类

<img src="https://raw.githubusercontent.com/Xav1erW/blog-imgs/master/202305311902031.png" alt="image-20230531190252671" style="zoom: 50%;" /><img src="https://raw.githubusercontent.com/Xav1erW/blog-imgs/master/202305311903858.png" alt="image-20230531190341628" style="zoom:50%;" />

这种表示方法有尺度问题：窗口大小的选择，可以选择不同大小的窗口，某一段尺度窗口大小纹理信息不怎么变化代表尺度合适。

只用边缘信息可能不够，那么我们可以使用更多的滤波器获得更多的特征，d个滤波器获得d维的特征，比如下图，考虑了尺度、方向，检测了边、条、点

<img src="https://raw.githubusercontent.com/Xav1erW/blog-imgs/master/202305311909508.png" alt="image-20230531190931129"  />

上述斜着的高斯核协方差矩阵中x，y相关

![image-20230531191239594](https://raw.githubusercontent.com/Xav1erW/blog-imgs/master/202305311912179.png)

获得到这些特征后，每个像素都对应一个48维的向量，我们可以做global avg pooling，最终用一个48维的向量表示图片做分类，或者直接拼接。（操作和卷积神经网络最后的分类头一模一样）

# 分割

过分割：把大物体中间分开

欠分割：小目标没分开

superpixel：把粒度提高了，相似的像素变成一个个小区块，图块比像素数量小

自顶向下：从整体的语义出发，通过语义的相似性去分割

自底向上：从底层像素的相似性出发来分割，聚类（无监督）

人的感受：哥斯达理论，群组感受，同样的线和箭头，不同的组合有不同的感受，会按照先验的知识去理解整体的语义

<img src="https://raw.githubusercontent.com/Xav1erW/blog-imgs/master/202306011616531.png" alt="image-20230601161553477" style="zoom:50%;" />

分割依据：距离近、相似（形状、颜色等）、共同的命运（运动方向）、共同的区域、平行的、对称的、连续性、封闭的几何形状

电梯按错：没有群组不好判断哪个数字对应哪个按钮

<img src="https://raw.githubusercontent.com/Xav1erW/blog-imgs/master/202306011622682.png" alt="image-20230601162215315" style="zoom:50%;" />

## 分割方法：聚类

将相似的像素聚类，比如使用RGB三个维度表示一个像素，三维空间中kmeans聚类；还可以基于灰度聚类（只有一维）

分割：语义分割、实例分割

为了可能实现实例分割、分割同类不同的物品，可以在像素特征中加入位置信息（但可能过分割，比如一个大的物体因为物体内像素位置差别大被分为多个类）

<img src="https://raw.githubusercontent.com/Xav1erW/blog-imgs/master/202306011627726.png" alt="image-20230601162732655" style="zoom:50%;" /><img src="https://raw.githubusercontent.com/Xav1erW/blog-imgs/master/202306011627017.png" alt="image-20230601162747032" style="zoom:50%;" />

kmeans：对外点敏感；同时有一个假设，球形的聚类（非球型用高斯混合模型）

## Mean Shift 均值漂移

不仅可以用于分割。

在寻找特征空间或模式中最大密度的中心

<img src="https://raw.githubusercontent.com/Xav1erW/blog-imgs/master/202306011633366.png" alt="image-20230601163329655" style="zoom:50%;" />

基本思想：对于一组点，随机选一个初始，画一个区域，之后计算区域的重心，将计算出的重心变成新区域的中心，重新计算新区域，重复该过程就能找到密度最大的中心。

如何分割：对于图像上点的特征，如果最终找到的中心是中心1，那么就分类为1，中心是2分割为2，如下图最终特征流向了多个中心

<img src="https://raw.githubusercontent.com/Xav1erW/blog-imgs/master/202306011637849.png" alt="image-20230601163741188" style="zoom:50%;" />

这样不需要指定中心，最后流向几个中心，就有几个类

优点：没有假定是球型的聚类；只有一个参数（窗口大小，决定了能不能跨域局部的密度中心，得到更大的分割）；可以得到不确定数量的类（受窗口大小影响）；不受噪声影响

缺点：特别依赖窗口大小；计算量大（可以改进，shift过程的路径上的点也可以直接当成一类）；对高维特征不好用（维度高的时候，可能点会很稀疏，窗口范围内就没几个点，导致无法准确找到重心进一步更新）。

## 图像看成图(graph)

每个像素都是一个图中的节点，每个边的权重是像素间的相似度。分割就是删除graph中的边，那么目标可以看作在图中找一个切分图的方法，使切掉的边权重最小。相似的像素都在一起。

<img src="https://raw.githubusercontent.com/Xav1erW/blog-imgs/master/202306011653504.png" alt="image-20230601165331740" style="zoom:50%;" />

相似性函数：假设定义好了特征向量和距离函数，通过下式控制相似性
$$
\exp\left(-\frac{1}{2\sigma^2}\text{dist}(x_i, x_j)^2\right)
$$
通过$\sigma^2$ 控制相似，当 $\sigma^2$ 小，那么距离变化很小的时候，相似性衰减快

<img src="https://raw.githubusercontent.com/Xav1erW/blog-imgs/master/202306011659237.png" alt="image-20230601165935069" style="zoom:50%;" />

### Minimun cut

最小割问题，图论中有方法，不叙述了。

但直接用可能出现切除很多独立的小块

#### normalize cut归一化图割：

$$
\frac{w(A,B)}{w(A,V)} + \frac{w(A,B)}{w(B,V)}
$$

$w(A,B)$ 意为A部分，B部分之间的所有有连接关系的点的连接边的求和，原本倾向于直接让w(A,B)最小，一边是A，一边是B，现在归一化的是除以**分割后**和所有点的的联系$w(A,V)$ 中V是所有点，这样不鼓励只有一条边被割（假设A是单独的一个点，那么w(A,V)肯定不大，因此整体值就增大）

如何计算：

前置步骤：首先选定图像像素的特征表示，RGB也好，RGB+XY也好；之后选择向量距离，L1，L2，cosine都行；选择相似度中的$\sigma$ ，之后步骤如下：

1. 定义一个W叫做邻接关系矩阵，记录相似度，$w_{i,j}$ 为第i个和第j个像素的相似度，特别的自己和自己的相似度定义成0。w是对称矩阵

2. 定义D为一个对角矩阵，第$d_{i,i}$是W中第i行所有结果相加的结果 $D(i,i) = \sum_j W(i,j)$

3. 理想中求出向量y，向量维度是像素个数，y内元素只有0和1，将像素分为两类，即将图割开。**每次割出来两类**

4. 那么我们需要最小化的cost形如：
   $$
   \frac{y^T(D-W)y}{y^TDy}
   $$

5. 拉格朗日法求最小化，上面分数形式最小化，例如$A/B$最小化，通常写成最小化$L=A+\lambda B$其中λ是拉格朗日乘子对于上式就是$L=y^T(D-W)y+\lambda y^TDy$

6. 求最小值，求导，由于$\lambda$可正可负，所以后项的正负号不影响，可以写成负号，求导等于0后可以得到
   $$
   (D-W)y=\lambda Dy
   $$

7. 结论：解为$(D-W)$第二小的特征值的特征向量，因为第一小对应的是0，标准解，不需要。

8. 求出来的y不是0和1，那么需要设定一个门限，大于门限为1，小于门限为0得到$\hat y$，确定门限可以带回到cost，哪个门限最小选择哪个门限

9. 使用$\hat y$将图分割

10. 循环的分割割出来的子图，**或者** 对于上面$(D-W)$分解出的所有特征向量聚类，可以这样理解：每个特征值对应一个分割方法，那么将分割方法聚类，聚类出k个类别，将相似的分割方法看成同一种分割方法，聚类中心作为分割方法的代表

如何表示像素特征：RGB固然是可以的，也可以使用**纹理表示**的方法（上节内容，用多个滤波核的结果表示成向量）纹理效果很好：

<img src="https://raw.githubusercontent.com/Xav1erW/blog-imgs/master/202306011958560.png" alt="image-20230601195854547" style="zoom:50%;" />

但是用纹理也有问题，可能会把边缘单独分为一个类（因为边缘的纹理特征和内部不一样）消除影响：分析中间轮廓，如果和外边轮廓相似认为是一个类

<img src="https://raw.githubusercontent.com/Xav1erW/blog-imgs/master/202306011959899.png" alt="image-20230601195954561" style="zoom:50%;" />

优点：一个总体的框架，可以选择很多种的特征

缺点：很高的计算和存储要求（pixel和pixel之间，高分辨率图像带来很高的特征数量）；有把物体平均分割的偏差（bias）

# 识别&分类

分类的级别：

* 整图的分类：猫、狗
* 目标检测：框出来哪里是物体，区域级的分割
* 分割：像素级的分类

识别任务有两种：

* 单实例识别：认出来确定的某一个物品，比如天安门、北邮西门

* 类别识别：识别某一类的，比如猫、狗、所有的大门

识别面临的问题：

1. 类别多，人类可以识别10000-30000种物品
2. 视角变化
3. 光照：对颜色等信息造成影响
4. 尺度：物品占图像的比例不同，希望能够对抗尺度变化
5. 形变：猫可能有很多变化，站着、坐着、躺着
6. 遮挡：
7. 背景杂波：<img src="https://raw.githubusercontent.com/Xav1erW/blog-imgs/master/202306012036208.png" alt="image-20230601203632944" style="zoom:50%;" />
8. 类内变化：同一种物品不一样，比如不同的椅子

识别系统：

* 表达：如何表达一个物体的类别
* 学习：如何从训练数据中学习一个分类器
* 识别：如何应用分类器到新的数据上

## 表达

一般用区域表达图像：比如SIFT、其他检测器、直接将图像均分为块、随机采样一些区域

可以直接将区域当成特征表示（词袋），也可以考虑区域的相对位置关系。

表达图像：词袋、纹理

我们想达到invariance，主要针对视角、光照、遮挡和尺度

### 词袋

将图像打散成块，装进“袋子”，对遮挡、视角的小变化、平移等不太敏感

<img src="https://raw.githubusercontent.com/Xav1erW/blog-imgs/master/202306012240130.png" alt="image-20230601224004975" style="zoom:50%;" />

起源：纹理表示，通过纹理基元的统计特征表示为直方图

<img src="https://raw.githubusercontent.com/Xav1erW/blog-imgs/master/202306012243546.png" alt="image-20230601224320506" style="zoom:50%;" />

1. 提取特征
2. 构建视觉词典
3. 把图像表示成词典

词典大小：一般取总特征数的1/10-1/100

### 空间金字塔表示

词袋缺少位置信息，使用空间金字塔表示，整图表达为一个词袋，图切成4份，每个区域也能表达成一个词袋；同理还能分成16份，把这些词袋全部拼接，作为整个图的表示，代表了一些空间上的含义

## 学习

产生式、判别式

判别：区分不同的分布

产生：建模事物的规律，直接学习分布

<img src="https://raw.githubusercontent.com/Xav1erW/blog-imgs/master/202306021340608.png" alt="image-20230602134015697" style="zoom:50%;" />

判别模型建模的是**后验概率**，生成模型建模的是**似然和先验概率**

<img src="https://raw.githubusercontent.com/Xav1erW/blog-imgs/master/202306012204499.png" alt="image-20230601220403384" style="zoom:50%;" />

先验描述整体上是斑马和不是斑马的概率，似然描述是斑马和不是斑马的图像的分布，后验描述给定图像是斑马和不是斑马的概率。根据上式，生成模型也能判别：建模出了似然和先验，那么对于给定的图片（相当于一个随机变量的值）可以计算出对应的似然和先验，那么就得到了后验概率比值。

学习就是去调整模型参数使某个指标最大。

标签等级：noise label 弱监督，可能标签是错的

标签是整个给的还是增量的：可能一次给出所有样本，还可能是增量学习，一天增加几个

先验：先验如何获取，从领域或行业知识获取

检测任务最终目标：从图像中的一堆窗口中判断窗口是否是目标（包含窗口的位置，角度，大小，类别）

# 目标检测

希望得到目标的位置：建立一个检测的模板，在图像中搜索哪一部分可以和模板匹配到。

难点：

* 光照、物体的姿态、杂波、遮挡、类内的外貌不同、视角；
* 不能和背景混在一起，那么如何建模背景，特征容易混淆的物体
* 如何高效搜索：不同尺度、不同位置的框很多
* 如何设计特征建模物体
* 如何解决不同视角：12年之前使用不同的模型训练不同的视角

## 人脸检测

检测和识别：检测拿出人脸，识别认识是哪个脸

单张图人脸较少，那么在背景处少检测，脸部分多检测

使用Adaboost

### Boosting算法

集成多个弱分类器：给定n个二分类的弱分类器，首先分类，选出分类精度最高的（大于50%），把他的权重加大

最后分类器：
$$
h(x) = \alpha_1h_1(x) + \alpha_2h_2(x) + \alpha_2h_2(x)+\cdots 
$$
单个分类器：
$$
h_j(x) = \left\{
\begin{aligned}
&1  \quad f_j(x)>\theta_j\\
&0
\end{aligned}
\right.
$$
总的分类器：
$$
h_j(x) = \left\{
\begin{aligned}
&1  \quad \sum_{t=1}^T \alpha_t h_t(x)>\frac{1}{2}\sum_{t=1}^T\alpha_t\\
&0
\end{aligned}
\right.
$$

### Boost在人脸检测

* 训练很慢但推理很快

主要思想

* 积分图，建立多个有分类能力的弱分类器
* 特征选择上应用boosting，使用上述弱分类器组合强分类器
* 使用级联块拒绝非人脸的区域

每个弱分类器有以下属性：

* 4个type，通过卷积核拿到，白区域减黑区域

  <img src="https://raw.githubusercontent.com/Xav1erW/blog-imgs/master/202306021021315.png" alt="image-20230602102145860" style="zoom:50%;" />

* pos：区域的位置x,y

* size：区域的面积w,h

最终每个分类器只负责自己pos和size区域的type特征，结果大于门限投1分否则0分作为分类结果

计算所有的卷积比较慢：加速使用**积分图**

#### 积分图

图中$i,j$位置的值是他左上方所有像素的求和

<img src="https://raw.githubusercontent.com/Xav1erW/blog-imgs/master/202306021030339.png" alt="image-20230602103031140" style="zoom:50%;" />
$$
I_\sum(x,y) = \sum_{x'\leq x; y' \leq y}i(x', y')
$$
有了积分图后，可以很方便的计算面积（区域内的像素求和）：

<img src="https://raw.githubusercontent.com/Xav1erW/blog-imgs/master/202306021034571.png" alt="image-20230602103407542" style="zoom:50%;" />
$$
S_{ABCD} = A-B-C+D
$$
三次加法就能得到任何区域的求和。

算法详细可以参考[人脸检测算法之Haar-Adaboost分类器原理 - 简书 (jianshu.com)](https://www.jianshu.com/p/7ab4986ddbe5)，下面简述步骤

步骤：

1. 对于每个弱分类器（type、pos、size）：输入所有的训练图片（可能有几万张）根据分类的结果，选择最优的门限，在可能的范围内枚举，选择最好的。

2. 选择分类器的最优的权重

   1. 所有样本权重归一化，如果是第一次，所有权重一样
   2. 对于每一个特征 $\epsilon_j = \sum_i w_i |h_j(x_i) - y_i|$其中的$w_i$是样本的权重，训练的时候使用的，用来给不同样本不同特征，从而筛选出不同的分类器
   3. 选择最低错误率的分类器

3. 更新权重（把分正确的样本权重缩小，相对的错误的权重就增大，能选出下一个分类出这些错误样本的分类器）
   $$
   w_{t+1, i} \gets w_{t,i}\beta_t^{1-|h_t(x_i) - y_i|} \qquad \beta_t =\frac{\epsilon_t}{1-\epsilon_t}
   $$

4. 最终分类器：
   $$
   h(x) = \left\{
   \begin{aligned}
   &1  \quad \sum_{t=1}^T \alpha_t h_t(x)>\frac{1}{2}\sum_{t=1}^T\alpha_t\\
   &0
   \end{aligned}
   \right.
   \qquad \alpha_t = \log \frac{1}{\beta_t}
   $$

需要强调的是：训练的时候数据只有单独的人脸，每个24\*24；推理的时候把图像割成不同大小的区域，reshape到24\*24，送到分类器中判断区域是不是人脸。

对快速检测的级联：

因为上面的检测虽然精度高，但是每张图有极大数量的特征，如果都送到上面的强分类器中需要很大的运算量和时间

* 将强分类器级联，每个强分类器不需要很高的精度（Precision），假阳率高没问题，但要尽可能的将正样本判断正确（高召回率）。比如只需要50%正确率，输出100个预测的正样本，只要其中50个是真正的正样本即可。
* 在前一个分类器的基础上，只分类被第一个分类器过滤的区域（每层只考虑前一层没有解决的问题）

<img src="https://raw.githubusercontent.com/Xav1erW/blog-imgs/master/202306021301735.png" alt="image-20230602130149486" style="zoom:50%;" />

分清楚：

* 漏检率，如果每个召回率99%，漏检1%，那么如果叠10层，那么最终只检测出$0.99^{10}\approx0.9$
* 误检率：如果每个误检率0.3，那么最终误检$0.3^{10} \approx 6*10^{-6}$

针对级联的，每个强分类器都需要学习，一个个训练，训练完挂在级联串后面，指定强分类器的指标，比如召回率0.99，查准率50%

级联的训练：

正样本：5000张脸24\*24，负样本：9500张非人脸图片中抽取出的300m负样本

每轮训练5000正，5000负

对于stage1：5000正样本，从9500张负样本中随机（大小、位置）扣出来5000张负样本，变为24\*24的

对于stage2：5000正样本不变，再从9500张负样本采样负样本，送给stage1，stage1分错的（负分类成正），送给stage2当作负样本，也这样采样出5000个负样本

后面的stage同理

检测出人脸后还可以做人脸识别：

1. 找出人脸
2. 定位眼睛嘴巴鼻子
3. 将上述五官缩放定位到标准模板
4. 最终分类

## 行人检测

<img src="https://raw.githubusercontent.com/Xav1erW/blog-imgs/master/202306021329678.png" alt="image-20230602132905637" style="zoom:50%;" />

对于每个行人的样本，计算梯度直方图

步骤：

图像必须是64\*128的，将图像分成16\*16的block，block分成4块，每块8\*8，在这个8\*8的区域内提取梯度方向直方图（9个方向，每40°分一次，因此是9维），那么一个block就是4\*9=36维。

对于第二个block，在第一个block的基础上步长为8，相当于重叠一半，继续这样计算。

这种方式可以得到105个区域，每个区域36维，最终得到3780维的HoG特征。

拿这个向量训练SVM。

之后对于给定的图像可以选取一个64\*128的区域，按上述方法提取特征，拿线性SVM分类，最终非极大抑制

本质就是通过SVM选择出了一个模板，测试的时候将特征和模板进行比较。

<img src="https://raw.githubusercontent.com/Xav1erW/blog-imgs/master/202306021348493.png" alt="image-20230602134831000" style="zoom:50%;" />

本身就是滑动窗口的方法：

* 非常时候人脸检测
* 车和行人检测也不错
* 对狗、猫等检测效果不好，因为他们会形变